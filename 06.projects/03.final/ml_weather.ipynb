{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ML :** Weather AUS\n",
    "\n",
    "#### _Rain in Australia_\n",
    "\n",
    "üü† `on work`\n",
    "\n",
    "---\n",
    "\n",
    "1. **Preprocessing**\n",
    "    * Extractions et pr√©parations\n",
    "    * Proto-mod√©lisation\n",
    "    * Traitements des valeurs\n",
    "    * Feature Selection\n",
    "    * Feature Engineering\n",
    "    * Feature Scaling\n",
    "2. **Modeling**\n",
    "    * Fonction d‚Äô√©valuation\n",
    "    * Entrainements multiples mod√®les\n",
    "    * Optimisation\n",
    "    * Analyse des erreurs\n",
    "    * Courbe d'aprentissage\n",
    "    * D√©cision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Built-in**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ML Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# - -\n",
    "# Evaluation, tuning, etc.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# - -\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# - -\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import average_precision_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# - - \n",
    "# Tools\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_x_y(dataframe:pd.DataFrame, target:str|list[str]) -> tuple :\n",
    "    \"\"\"Extract Features and Target from dataset\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Dataframe to extract columns from\n",
    "        target (str | list[str]): Target name\n",
    "\n",
    "    Returns:\n",
    "        tuple: Feature as X, and Label as y\n",
    "    \"\"\"\n",
    "\n",
    "    y = dataframe[target] \n",
    "    X = dataframe.drop(columns=target)\n",
    "\n",
    "    print(y.unique())\n",
    "    print(X.columns.to_list())\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cm(cm:list, name:str) -> None :\n",
    "    \"\"\"Save a Confusion Matrix as CSV file in `./_outputs/` subdirectory\n",
    "\n",
    "    Args:\n",
    "        cm (list): Confusion Matrix built from `sklearn.metrics`\n",
    "        name (str): A lowercase spaceless text for file name\n",
    "    \"\"\"\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        'Predict. Yes': [cm[0,0], cm[1,0]],\n",
    "        'Predict. No': [cm[1,0], cm[1,1]]\n",
    "    }, index=['True Yes', 'True No'])\n",
    "    \n",
    "    df.to_csv(f'./_outputs/cm_{name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour codes\n",
    "mean_c = '#FFFFFF'\n",
    "median_c = '#c2e800'\n",
    "default_c = '#336699'\n",
    "palette_c = [\n",
    "    '#b8e600', # Sunny\n",
    "    '#00bfff' # Rainy\n",
    "]\n",
    "\n",
    "# Pandas\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.min_rows = 6\n",
    "\n",
    "# Matplotlib\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = '#242428'\n",
    "plt.rcParams['axes.facecolor'] = '#242428'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weather AUS**\n",
    "\n",
    "[Rain in Australia](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1007.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1009.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1008.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  Evaporation  Sunshine WindGustDir  WindGustSpeed  \\\n",
       "0  2008-12-01   Albury          NaN       NaN           W           44.0   \n",
       "1  2008-12-02   Albury          NaN       NaN         WNW           44.0   \n",
       "2  2008-12-03   Albury          NaN       NaN         WSW           46.0   \n",
       "\n",
       "  WindDir3pm  Humidity3pm  Cloud3pm  Temp3pm RainToday RainTomorrow  Pressure  \n",
       "0        WNW         22.0       NaN     21.8        No           No   1007.40  \n",
       "1        WSW         25.0       NaN     24.3        No           No   1009.20  \n",
       "2        WSW         30.0       2.0     23.2        No           No   1008.15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_file_path = './_datasets/weather_data_prepare.csv'\n",
    "weather_data = pd.read_csv(weather_file_path)\n",
    "# weather_data['RainTomorrow'] = weather_data['RainTomorrow'].astype('category')\n",
    "\n",
    "weather_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Help**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Categorical Variables - Kaggle](https://www.kaggle.com/code/alexisbcook/categorical-variables/tutorial)\n",
    "\n",
    "The scikit-learn algorithm for MI treats discrete features differently from continuous features. Consequently, you need to tell it which are which. As a rule of thumb, anything that must have a float dtype is not discrete. Categoricals (object or categorial dtype) can be treated as discrete by giving them a label encoding. (You can review label encodings in our Categorical Variables lesson.)\n",
    "\n",
    "One-hot encoding generally does not perform well if the categorical variable takes on a large number of values (i.e., you generally won't use it for variables taking more than 15 different values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mutual Information - Kaggle](https://www.kaggle.com/code/ryanholbrook/mutual-information/tutorial)\n",
    "\n",
    "_Locate features with the most potential_\n",
    "\n",
    "A great first step is to construct a ranking with a feature utility metric, a function measuring associations between a feature and the target. Then you can choose a smaller set of the most useful features to develop initially and have more confidence that your time will be well spent.\n",
    "\n",
    "The metric we'll use is called **\"mutual information\"**. Mutual information is a lot like correlation in that it measures a relationship between two quantities. The advantage of mutual information is that **it can detect any kind of relationship**, while correlation **only detects linear relationships.**\n",
    "\n",
    "Mutual information is a great general-purpose metric and especially useful at the start of feature development when you might not know what model you'd like to use yet. It is :\n",
    "- easy to use and interpret,\n",
    "- computationally efficient,\n",
    "- theoretically well-founded,\n",
    "- resistant to overfitting, and,\n",
    "- able to detect any kind of relationship\n",
    "\n",
    "Technical note: What we're calling uncertainty is measured using a quantity from information theory known as \"entropy\". The entropy of a variable means roughly: \"how many yes-or-no questions you would need to describe an occurance of that variable, on average.\" The more questions you have to ask, the more uncertain you must be about the variable. Mutual information is how many questions you expect the feature to answer about the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Imbalanced Classification (theory) - Neptune.ia](https://neptune.ai/blog/how-to-deal-with-imbalanced-classification-and-regression-data)\n",
    "\n",
    "[Imbalanced Classiffication (example) - Elite DataScience](https://elitedatascience.com/imbalanced-classes)\n",
    "\n",
    "[Resampling Strategies - Kaggle](https://www.kaggle.com/code/rafjaa/resampling-strategies-for-imbalanced-datasets/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **1.** Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.1** - Extractions et pr√©parations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des _Features_ et du _label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' nan]\n",
      "['Date', 'Location', 'Evaporation', 'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir3pm', 'Humidity3pm', 'Cloud3pm', 'Temp3pm', 'RainToday', 'Pressure']\n"
     ]
    }
   ],
   "source": [
    "X, y = extract_x_y(weather_data, 'RainTomorrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation des donn√©es d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.DataFrame({\n",
    "    'Label Entrainement': y_train.describe(),\n",
    "    'Label Test': y_test.describe()\n",
    "    }),\n",
    "    pd.Series([\n",
    "        (y_train.describe()[3] / y_train.count()) * 100,\n",
    "        (y_test.describe()[3] / y_test.count()) * 100\n",
    "    ], name='percent of no', index=['Label Entrainement', 'Label Test']).to_frame().T\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodage des variables cat√©gorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- setting handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and\n",
    "- setting sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = []\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[object_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_test.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [!] - For Regression with 'mean_absolute_error' => change for classification mode\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_dataset(OH_X_train, OH_X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.2** - Proto-mod√©lisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D√©finition et entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.3** - Traitements des valeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valeurs aberrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_majority, count_minority = weather_prepared['RainTomorrow'].value_counts()\n",
    "\n",
    "display(\n",
    "    count_majority,\n",
    "    count_minority\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_majority = weather_prepared[weather_prepared['RainTomorrow'] == 0]\n",
    "df_class_minority = weather_prepared[weather_prepared['RainTomorrow'] == 1]\n",
    "\n",
    "display(\n",
    "    df_class_majority,\n",
    "    df_class_minority\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_class_majority, \n",
    "                                 replace=False,             # sample without replacement\n",
    "                                 n_samples=count_minority,  # to match minority class\n",
    "                                 random_state=5)            # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_class_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled['RainTomorrow'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.4** - Traitements Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_KF = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "gd_param = {'max_depth': np.arange(1,25), 'criterion' : ['entropy', 'gini']}\n",
    "\n",
    "m1_gd_DT = GridSearchCV(DecisionTreeClassifier(), gd_param, cv=cv_KF)\n",
    "m1_gd_DT.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
